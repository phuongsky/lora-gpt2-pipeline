model:
  base_model: "openai/gpt-oss-120b"
  quantization: "int4"

lora:
  r: 8
  lora_alpha: 32
  dropout: 0.1
  target_modules: ["c_attn"]

dataset:
  train_dataset: "jxm/gpt-oss20b-samples"
  valid_dataset: "jxm/gpt-oss20b-samples"
  text_column: "text"
  max_length: 128

training:
  output_dir: "./outputs"
  batch_size: 4
  epochs: 3
  learning_rate: 5e-5
  logging_steps: 10
  save_steps: 100
  fp16: false
  seed: 42
  deepspeed: null
  report_to: "wandb"
  run_name: "psm-run1"

hf_hub:
  repo_id: "phuongsky/psm"
  push_to_hub: true
